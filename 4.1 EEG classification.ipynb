{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install scipy\n",
    "!pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import gdown\n",
    "\n",
    "folder_id = \"1IBMYahLwJ5pY9b-f4gCm_LZPCcYccH6h\"\n",
    "\n",
    "gdown.download_folder(\n",
    "    id=folder_id,\n",
    "    quiet=False,\n",
    "    use_cookies=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "sampling_freq = 128\n",
    "FOCUSED_CLASS = 0\n",
    "UNFOCUSED_CLASS = 1\n",
    "DROWNSY_CLASS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "path = \"/content/EEG Data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "files = os.listdir(path)\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "columns = [\n",
    "    'ED_COUNTER',    'ED_INTERPOLATED',    'ED_RAW_CQ',    'ED_AF3',    'ED_F7',\n",
    "    'ED_F3',    'ED_FC5',    'ED_T7',    'ED_P7',    'ED_O1',\n",
    "    'ED_O2',    'ED_P8',    'ED_T8',    'ED_FC6',    'ED_F4',\n",
    "    'ED_F8',    'ED_AF4',    'ED_GYROX',    'ED_GYROY',    'ED_TIMESTAMP',\n",
    "    'ED_ES_TIMESTAMP',    'ED_FUNC_ID',    'ED_FUNC_VALUE',    'ED_MARKER',    'ED_SYNC_SIGNAL'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def get_state(timestamp):\n",
    "    if timestamp <= 10*128*60:\n",
    "        return FOCUSED_CLASS\n",
    "    elif timestamp > 20*128*60:\n",
    "        return UNFOCUSED_CLASS\n",
    "    else:\n",
    "        return DROWNSY_CLASS\n",
    "\n",
    "# Scale data\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def get_EEG_data(data_root, filename):\n",
    "    hz = sampling_freq\n",
    "    mat = scipy.io.loadmat(data_root +\"/\"+ filename)\n",
    "    data = mat[\"o\"][\"data\"][0,0]\n",
    "    eeg_df = pd.DataFrame(data, columns=columns)\n",
    "    eeg_df = eeg_df.filter(['ED_AF3', 'ED_F7', 'ED_F3', 'ED_FC5',\n",
    "                            'ED_T7', 'ED_P7', 'ED_O1', 'ED_O2',\n",
    "                            'ED_P8', 'ED_T8', 'ED_FC6', 'ED_F4',\n",
    "                            'ED_F8', 'ED_AF4'])\n",
    "    labels = ['AF3','F7', 'F3','FC5','T7','P7','O1','O2','P8','T8', 'FC6','F4','F8','AF4']\n",
    "    eeg_df.columns = labels\n",
    "    eeg_df = pd.DataFrame(scaler.fit_transform(eeg_df), columns=eeg_df.columns)\n",
    "    eeg_df.reset_index(inplace=True)\n",
    "    eeg_df.rename(columns={'index': 'timestamp'}, inplace=True)\n",
    "\n",
    "    eeg_df['state'] = eeg_df['timestamp'].apply(get_state)\n",
    "\n",
    "    return eeg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "dataset = []\n",
    "# For each file, print # minutes of data\n",
    "for filename in files:\n",
    "    data = get_EEG_data(path, filename)\n",
    "    dataset.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "type(dataset), type(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def split_epochs(data, hz, epoch_length=4, step_size=0.125):\n",
    "  step = int(epoch_length * hz - step_size * hz)\n",
    "  offset = int(epoch_length * hz)\n",
    "  starts = []\n",
    "  current = 0\n",
    "\n",
    "# Generate the first series\n",
    "  while current + offset <= data.shape[0]:\n",
    "    starts.append(current)\n",
    "    current += step\n",
    "\n",
    "  # Generate the second series using a list comprehension\n",
    "  ends = [x + offset for x in starts]\n",
    "\n",
    "  # Lưu trữ các epoch\n",
    "  epochs = []\n",
    "\n",
    "  # Cắt các epoch từ tín hiệu\n",
    "  for i in range(len(starts)):\n",
    "    epoch = data.iloc[starts[i]:ends[i]]\n",
    "    epochs.append(epoch)\n",
    "\n",
    "  return epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "epochs_data = []\n",
    "for eeg in dataset:\n",
    "  epochs = split_epochs(eeg, sampling_freq)\n",
    "  for epoch in epochs:  # Iterate directly over the epochs\n",
    "    epochs_data.append(epoch)  # Append each DataFrame to the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "len(epochs_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "len(epochs_data), type(epochs_data), type(epochs_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset # Added this import\n",
    "\n",
    "class EEGDataset(Dataset):\n",
    "  def __init__(self, dataframes, target_column='state', wavelet='db6', level=4):\n",
    "    self.data = []\n",
    "    self.targets = []\n",
    "    self.scaler = StandardScaler()\n",
    "\n",
    "    print(f\"Processing {len(dataframes)} dataframes...\")\n",
    "\n",
    "    for df in dataframes:\n",
    "      # Extract target\n",
    "      self.targets.append(df[target_column].mode()[0])\n",
    "\n",
    "      # Process features\n",
    "      feature = df.drop(columns=[target_column, 'timestamp'], errors='ignore')\n",
    "      self.data.append(feature.values)\n",
    "\n",
    "    # Convert lists to tensors AFTER the loop\n",
    "    self.data = torch.tensor(self.data, dtype=torch.float32)\n",
    "    self.targets = torch.tensor(self.targets, dtype=torch.long) # Changed dtype to torch.long\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.targets)  # Should match the number of targets, not individual rows\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    return self.data[idx], self.targets[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Create dataset\n",
    "dataset = EEGDataset(epochs_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "dataset.targets, len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "dataset.data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class TransformerClassifier(nn.Module):\n",
    "    def __init__(self, input_dim=14, num_classes=3, seq_len=512, d_model=64, nhead=4, num_layers=2):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Linear(input_dim, d_model)\n",
    "        self.pos_encoding = nn.Parameter(torch.randn(1, seq_len, d_model))\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=2 * d_model,\n",
    "            dropout=0.1,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool1d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(d_model, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x) + self.pos_encoding[:, :x.size(1), :]\n",
    "        x = self.encoder(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install pytorch-lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from pytorch_lightning.core.module import LightningModule # Added this import\n",
    "\n",
    "class LitTransformer(LightningModule):\n",
    "    def __init__(self, input_dim=14, num_classes=2, seq_len=512, lr=1e-3):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.model = TransformerClassifier(input_dim, num_classes, seq_len)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        # Track metrics\n",
    "        self.train_losses = []\n",
    "        self.train_accuracies = []\n",
    "        self.val_losses = []\n",
    "        self.val_accuracies = []\n",
    "\n",
    "        # Internal accumulators for training metrics\n",
    "        self._train_epoch_losses = []\n",
    "        self._train_epoch_accs = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y = batch\n",
    "        logits = self(X)\n",
    "        loss = self.criterion(logits, y)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        acc = (preds == y).float().mean()\n",
    "\n",
    "        # Store per-batch metrics to average later\n",
    "        self._train_epoch_losses.append(loss.item())\n",
    "        self._train_epoch_accs.append(acc.item())\n",
    "\n",
    "        self.log('train_loss', loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log('train_acc', acc, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        # Compute mean metrics for this epoch\n",
    "        if self._train_epoch_losses:\n",
    "            avg_loss = np.mean(self._train_epoch_losses)\n",
    "            avg_acc = np.mean(self._train_epoch_accs)\n",
    "\n",
    "            self.train_losses.append(avg_loss)\n",
    "            self.train_accuracies.append(avg_acc)\n",
    "\n",
    "            print(f\"\\nEpoch {self.current_epoch + 1}: train_loss={avg_loss:.4f}, train_acc={avg_acc * 100:.2f}%\")\n",
    "\n",
    "            # Reset accumulators\n",
    "            self._train_epoch_losses.clear()\n",
    "            self._train_epoch_accs.clear()\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        X, y = batch\n",
    "        logits = self(X)\n",
    "        loss = self.criterion(logits, y)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        acc = (preds == y).float().mean()\n",
    "\n",
    "        self.log('val_loss', loss, on_epoch=True, prog_bar=True)\n",
    "        self.log('val_acc', acc, on_epoch=True, prog_bar=True)\n",
    "        return {'val_loss': loss, 'val_acc': acc}\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        metrics = self.trainer.callback_metrics\n",
    "        val_loss = metrics['val_loss'].item()\n",
    "        val_acc = metrics['val_acc'].item()\n",
    "\n",
    "        self.val_losses.append(val_loss)\n",
    "        self.val_accuracies.append(val_acc)\n",
    "        print(f\"Epoch {self.current_epoch + 1}: val_loss={val_loss:.4f}, val_acc={val_acc * 100:.2f}%\")\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.hparams.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(dataset))  # 80% cho training\n",
    "val_size = int(0.10 * len(dataset))  # 10% cho validation\n",
    "test_size = len(dataset) - train_size - val_size # 10% cho validation\n",
    "\n",
    "# Chia dataset thành train và val\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# Tạo DataLoader cho train và val\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model = LitTransformer(\n",
    "    input_dim=14,\n",
    "    num_classes=3,  # Changed from 2 to 3 to accommodate DROWNSY_CLASS\n",
    "    seq_len=512,\n",
    "    lr=1e-3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from pytorch_lightning import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    max_epochs=10,\n",
    "    accelerator='auto',\n",
    "    devices=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Ensure consistent length\n",
    "min_len = min(len(model.train_losses), len(model.val_losses))\n",
    "epochs = range(1, min_len + 1)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# ------------------------------\n",
    "# Plot LOSS\n",
    "# ------------------------------\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, model.train_losses[:min_len], label='Train Loss', marker='o')\n",
    "plt.plot(epochs, model.val_losses[:min_len], label='Validation Loss', marker='o')\n",
    "plt.title('Epoch vs Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# ------------------------------\n",
    "# Plot ACCURACY\n",
    "# ------------------------------\n",
    "min_len_acc = min(len(model.train_accuracies), len(model.val_accuracies))\n",
    "epochs_acc = range(1, min_len_acc + 1)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_acc, [x * 100 for x in model.train_accuracies[:min_len_acc]],\n",
    "         label='Train Accuracy', marker='o')\n",
    "plt.plot(epochs_acc, [x * 100 for x in model.val_accuracies[:min_len_acc]],\n",
    "         label='Validation Accuracy', marker='o', color='green')\n",
    "plt.title('Epoch vs Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
